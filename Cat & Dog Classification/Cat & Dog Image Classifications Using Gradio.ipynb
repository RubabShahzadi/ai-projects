{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPqvIhiwU2tcEndVVKMbeIS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":975},"id":"XIqcjzDNgyqO","executionInfo":{"status":"ok","timestamp":1759253380681,"user_tz":-300,"elapsed":166119,"user":{"displayName":"rubab shahzadi","userId":"04394958811081671382"}},"outputId":"472cc735-6d3f-4eb5-825a-323cfcc18c9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n","Your Kaggle username: rubabshahzadi\n","Your Kaggle Key: ··········\n","Dataset URL: https://www.kaggle.com/datasets/jakupymeraj/cats-and-dogs-image-dataset\n","Downloading cats-and-dogs-image-dataset.zip to ./cats-and-dogs-image-dataset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 217M/217M [00:00<00:00, 503MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Found 160 images belonging to 2 classes.\n","Found 40 images belonging to 2 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Epoch 1/3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 629ms/step - accuracy: 0.6947 - loss: 0.5711 - val_accuracy: 0.8500 - val_loss: 0.4084\n","Epoch 2/3\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 445ms/step - accuracy: 0.9039 - loss: 0.2782 - val_accuracy: 0.9000 - val_loss: 0.2621\n","Epoch 3/3\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 532ms/step - accuracy: 0.9281 - loss: 0.2168 - val_accuracy: 0.9250 - val_loss: 0.2089\n","It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://fc791a971cff538507.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://fc791a971cff538507.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":1}],"source":["# Install dependencies\n","!pip install opendatasets gradio tensorflow --quiet\n","\n","import opendatasets as od\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, models\n","import gradio as gr\n","import numpy as np\n","import os\n","import shutil\n","\n","# Download dataset\n","od.download(\"https://www.kaggle.com/datasets/jakupymeraj/cats-and-dogs-image-dataset\")\n","\n","# Copy small number of images for quick training\n","base_path = \"/content/cats-and-dogs-image-dataset/dataset/training_set\"\n","small_train_path = \"/content/small_train\"\n","os.makedirs(small_train_path + \"/cats\", exist_ok=True)\n","os.makedirs(small_train_path + \"/dogs\", exist_ok=True)\n","\n","for cls in ['cats', 'dogs']:\n","    for i, img in enumerate(os.listdir(f\"{base_path}/{cls}\")):\n","        if i >= 100: break  # Use 100 per class for better learning\n","        shutil.copy(f\"{base_path}/{cls}/{img}\", f\"{small_train_path}/{cls}\")\n","\n","# Image parameters\n","IMG_SIZE = (160, 160)\n","BATCH_SIZE = 16\n","\n","# Data preprocessing\n","train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    small_train_path,\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    subset='training'\n",")\n","\n","val_generator = train_datagen.flow_from_directory(\n","    small_train_path,\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    subset='validation'\n",")\n","\n","# Load pre-trained MobileNetV2 without top layer\n","base_model = tf.keras.applications.MobileNetV2(input_shape=(*IMG_SIZE, 3),\n","                                               include_top=False,\n","                                               weights='imagenet')\n","base_model.trainable = False  # Freeze base\n","\n","# Add custom layers\n","model = models.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train (only final layer) for quick demo\n","model.fit(train_generator, validation_data=val_generator, epochs=3)\n","\n","# Prediction function\n","def classify_image(img):\n","    img = img.resize(IMG_SIZE)\n","    img_array = tf.keras.preprocessing.image.img_to_array(img)\n","    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    prediction = model.predict(img_array)[0][0]\n","    return \"Dog 🐶\" if prediction > 0.5 else \"Cat 🐱\"\n","\n","# Gradio UI\n","interface = gr.Interface(\n","    fn=classify_image,\n","    inputs=gr.Image(type=\"pil\"),\n","    outputs=gr.Text(label=\"Prediction\"),\n","    title=\"Cat vs Dog Classifier (MobileNetV2 Transfer Learning)\",\n","    description=\"Upload a cat or dog image. Trained on 200 images for quick and accurate prediction.\"\n",")\n","\n","interface.launch()"]}]}